{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from os.path import join\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, classification_report, precision_score, recall_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ffd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manipulations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24055aec",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce385136",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = join('data', '05_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(join(data_dir, 'all_data_combined.csv'))\n",
    "data = raw_data.copy()\n",
    "data_gf = pd.read_csv(join(data_dir, 'all_data_combined_GF.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['CT//StudyDate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Location', 'Behandlungsplan//Behandlungsprotokoll::Sauerstofftherapie']\n",
    "data.drop(drop_columns, inplace=True, axis=1)\n",
    "data_gf.drop(drop_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization\n",
    "perform_ho = True\n",
    "n_iter = 10\n",
    "cv = 3\n",
    "verbose = 3\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fa5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('data', 'features', 'selected_features.json'), 'r') as f:\n",
    "    features = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5fecb",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_gf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target_3_DEC'] = df['Target_3'].map({0: 'Non-severe', 1: 'Severe'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Target_3_DEC'\n",
    "figure, axis = plt.subplots(1, 2, figsize=(10,6))\n",
    "figure.tight_layout(pad=5.0)\n",
    "plot_features = ['Number_comorbidities',\n",
    "                 'CT//Konsolidierung::Anzahl betroffener Lappen'\n",
    "                ]\n",
    "y_labels = ['Number of comorbidities', 'Number of affected lung lobes (consolidation)']\n",
    "\n",
    "for i, col in enumerate(plot_features):\n",
    "    plot = sns.boxplot(data=df, x=target_variable, y=col, ax=axis[i], color='#c4c4c4', width=0.3, linewidth=0.8)\n",
    "    plot.set_xlabel(\"Disease progression\",fontsize=11, labelpad=10)\n",
    "    plot.set_ylabel(y_labels[i], fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18910f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "comorbs = [col for col in df.columns if 'Komorbiditäten' in col]\n",
    "for i, comorb in enumerate(comorbs):\n",
    "    df[comorb] = df[comorb].replace(-1, 0)\n",
    "    g = df.groupby(comorb)['Target_3_DEC'].value_counts(normalize=True).unstack()\n",
    "    ax = g.plot(kind='bar', figsize=(7, 5), xlabel=comorb.split('::')[1].replace('##CODE', ''), ylabel='Percentage', rot=0, stacked=True)  # , ax=axe[i]\n",
    "    ax.legend(title='Disease progression', bbox_to_anchor=(1, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287deea",
   "metadata": {},
   "source": [
    "## Risk model\n",
    "\n",
    "**Target variables**\n",
    "\n",
    "* **Target 0: Höchster Behandlungsstatus**\n",
    "\n",
    "Unique values: 0 - Unbekannt 1 - Ambulant 2 - Notaufnahme 3 - Stationär 4 - IMC 5 - ICU\n",
    "\n",
    "* **Target 2: Höchster Beatmungsbedarf**\n",
    "\n",
    "Unique values: 0 - Unbekannt 1 - Nasenbrille 2 - Nicht-invasive Beatmung 3 - Invasive Beatmung 4 - Invasive Beatmung mit ECMO\n",
    "\n",
    "* **Target 3: Schweregrad der COVID-19 Erkrankung**\n",
    "\n",
    "Unique values: 1 - Schwer 0 - Leicht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b12926",
   "metadata": {},
   "source": [
    "### Feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "forbidden_features = ['PatientID', 'Target_0', 'Target_2', 'Target_3']\n",
    "not_incl_features = [col for col in data.columns if col not in forbidden_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_comorb_features = [\n",
    "    'CT//Milchglasareal::Schweregrad (Mittellappen rechts)',\n",
    "    'CT//Milchglasareal::Schweregrad (Oberlappen links)',\n",
    "    'CT//Milchglasareal::Schweregrad (Oberlappen rechts)',\n",
    "    'CT//Milchglasareal::Schweregrad (Unterlappen links)',\n",
    "    'CT//Milchglasareal::Schweregrad (Unterlappen rechts)',\n",
    "    'CT//Severity Scores::Lunge Mittelfeld links',\n",
    "    'CT//Severity Scores::Lunge Mittelfeld rechts',\n",
    "    'CT//Severity Scores::Lunge Oberfeld links',\n",
    "    'CT//Severity Scores::Lunge Oberfeld rechts',\n",
    "    'CT//Severity Scores::Lunge Unterfeld links',\n",
    "    'CT//Severity Scores::Lunge Unterfeld rechts',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Emphysem',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Lungenfibrose',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Gibt es andere bekannte Komorbiditäten?',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Chronisch obstruktive Lungenerkrankung',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Bluthochdruck',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Herzerkrankungen',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Stauung/Ödem',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Dialyse',\n",
    "    'Klinisch-anamnestische Information//Komorbiditäten aus Arztbrief::Diabetes mellitus##CODE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4dfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset I: All features (data)\n",
    "I_features = [col for col in data.columns if col not in forbidden_features]\n",
    "\n",
    "# Subset II: All features + generated features (data_gf)\n",
    "II_features = [col for col in data_gf.columns if col not in forbidden_features]\n",
    "\n",
    "# Subset III: Generated features reduced (data_gf)\n",
    "III_features = [col for col in data_gf.columns if col not in drop_comorb_features + forbidden_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset IV: Chi-square selected features (data_gf)\n",
    "ordinal_features_significant = select_significants(data_gf, features['ordinal'], 'Target_3')\n",
    "non_ordinal_features_significant = select_significants(data_gf, features['nominal'], 'Target_3')\n",
    "\n",
    "selected_features = ordinal_features_significant + non_ordinal_features_significant + features['num'] + features['generated']\n",
    "IV_features = [col for col in selected_features if col not in drop_comorb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset V: Image-related features (data)\n",
    "image_features = [col for col in data.columns if 'CT' in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c60a7",
   "metadata": {},
   "source": [
    "#### Hold-out test dataset and selection of feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X_s, target_X_s_test, target_y_s, target_y_s_test, target_split_indices = {}, {}, {}, {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in [0, 2, 3]:\n",
    "    tmp_X = data.copy()\n",
    "    tmp_y = tmp_X.pop(f'Target_{target}')\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(tmp_X, tmp_y, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "#     Use the following three lines if you haven't already created lists of train/val and test indices\n",
    "    target_split_indices[target] = {'train/val': tmp_X_train.index.tolist(), 'test': tmp_X_test.index.tolist()}\n",
    "    with open(join('data', 'indices', f'split_indices_target_{target}.json'), 'w') as fp:\n",
    "        json.dump(target_split_indices[target], fp)\n",
    "        \n",
    "    # Use the following two lines if you've already created lists of train/val and test indices\n",
    "#     with open(join('data', 'indices', f'split_indices_target_{target}.json'), 'r') as f:\n",
    "#         target_split_indices[target] = json.load(f)\n",
    "\n",
    "    # Create train/val dataset\n",
    "    tmp_data = data.iloc[target_split_indices[target]['train/val']].reset_index(drop=True)\n",
    "    tmp_data_gf = data_gf.iloc[target_split_indices[target]['train/val']].reset_index(drop=True)\n",
    "    \n",
    "    X_I = tmp_data[[col for col in tmp_data.columns if col not in forbidden_features]]\n",
    "    X_II = tmp_data_gf[[col for col in tmp_data_gf.columns if col not in forbidden_features]]\n",
    "    X_III = tmp_data_gf[[col for col in tmp_data_gf.columns if col not in drop_comorb_features + forbidden_features]]\n",
    "    X_IV = tmp_data_gf[selected_features]\n",
    "    X_V = tmp_data[image_features]\n",
    "    target_X_s[target] = [X_I, X_II, X_III, X_IV, X_V]\n",
    "    \n",
    "    target_y_s[target] = tmp_data[f'Target_{target}']\n",
    "    \n",
    "    # Create test dataset\n",
    "    tmp_test_data = data.iloc[target_split_indices[target]['test']].reset_index(drop=True)\n",
    "    tmp_test_data_gf = data_gf.iloc[target_split_indices[target]['test']].reset_index(drop=True)\n",
    "    \n",
    "    X_I_test = tmp_test_data[[col for col in tmp_test_data.columns if col not in forbidden_features]]\n",
    "    X_II_test = tmp_test_data_gf[[col for col in tmp_test_data_gf.columns if col not in forbidden_features]]\n",
    "    X_III_test = tmp_test_data_gf[[col for col in tmp_test_data_gf.columns if col not in drop_comorb_features + forbidden_features]]\n",
    "    X_IV_test = tmp_test_data_gf[selected_features]\n",
    "    X_V_test = tmp_test_data[image_features]\n",
    "    target_X_s_test[target] = [X_I_test, X_II_test, X_III_test, X_IV_test, X_V_test]\n",
    "    \n",
    "    target_y_s_test[target] = tmp_test_data[f'Target_{target}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc20d0",
   "metadata": {},
   "source": [
    "### Target 0: Höchster Behandlungsstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbe946",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0\n",
    "X_s = target_X_s[target]\n",
    "y = target_y_s[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a036ea",
   "metadata": {},
   "source": [
    "#### Results with combination of classes but no upsampling\n",
    "Combine class 0,1 and 2 into one class. Classes now:\n",
    "* 0 -> Nicht beantwortet, Ambulant, Notaufnahme\n",
    "* 1 -> Stationär\n",
    "* 2 -> IMC\n",
    "* 3 -> ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_replaced = y.replace({1:0, 2:0, 3:1, 4:2, 5:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_replaced.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_results = {\n",
    "    'feature_subgroup': [],\n",
    "    'model': [],\n",
    "    'reference': [],\n",
    "    'accuracy': [],\n",
    "    'PPV': [],\n",
    "    'sensitivity': [],\n",
    "    'f1_score': [],\n",
    "    'p-value': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_model_type, best_i, best_X_train, best_y_train, best_X_test, best_y_test, best_acc = None, None, None, None, None, None, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, X in enumerate(X_s):\n",
    "    print(f'Feature subset {i+1}')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_replaced, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    for model_type in ['Random forest', 'Gradient boosting']:\n",
    "        print(model_type)\n",
    "        model = RandomForestClassifier(random_state=random_state) if model_type == 'Random forest' else GradientBoostingClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Perform McNemar significance test\n",
    "        majority_vote = np.array([y_test.mode()[0]] * len(y_test))\n",
    "        reference = accuracy_score(y_test, majority_vote)\n",
    "        d_results['reference'].append(reference)\n",
    "        mcnemar_result = mcnemar(table=[[sum(y_test & predictions), sum(~y_test & predictions)],\n",
    "                                      [sum(y_test & ~majority_vote), sum(~y_test & ~majority_vote)]], correction=True)\n",
    "        p_value = mcnemar_result.pvalue\n",
    "        d_results['p-value'].append(p_value)\n",
    "        \n",
    "        d_results['model'].append(model_type)\n",
    "\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        d_results['feature_subgroup'].append(i+1)\n",
    "        d_results['accuracy'].append(acc)\n",
    "        d_results['PPV'].append(precision_score(y_test, predictions, average='weighted'))\n",
    "        d_results['sensitivity'].append(recall_score(y_test, predictions, average='weighted'))\n",
    "        d_results['f1_score'].append(f1_score(y_test, predictions, average='weighted'))\n",
    "        print(f'Accuracy: {acc}')\n",
    "        print(classification_report(y_test, predictions))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_i = i+1\n",
    "            best_X_train = X_train\n",
    "            best_y_train = y_train\n",
    "            best_X_test = X_test\n",
    "            best_y_test = y_test\n",
    "            best_model = model\n",
    "            best_model_type = model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ba1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best accuracy: {best_acc}\\nBest model type: {best_model_type}\\nBest feature subset: {best_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9968b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(d_results)\n",
    "\n",
    "d_results_restructured = {\n",
    "    'feature_subset': [],\n",
    "    'accuracy': [],\n",
    "    'sensitivity': [],\n",
    "    'PPV': []\n",
    "}\n",
    "\n",
    "for f in [1,2,3,4,5,6]:\n",
    "    d_results_restructured['feature_subset'].append(f)\n",
    "    for metric in ['accuracy', 'sensitivity', 'PPV']:\n",
    "        rf = results[(results['feature_subgroup'] == f) & (results['model'] == 'Random forest')][metric].reset_index(drop=True).iloc[0]\n",
    "        gb = results[(results['feature_subgroup'] == f) & (results['model'] == 'Gradient boosting')][metric].reset_index(drop=True).iloc[0]\n",
    "        m_str = f'{gb*100:.2f}% ({rf*100:.2f}%)'\n",
    "        d_results_restructured[metric].append(m_str)\n",
    "\n",
    "pd.DataFrame(d_results_restructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b015143",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecd144",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(best_X_train.columns)\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Sort importances and get the indices of the 10 most important features\n",
    "sorted_idx = np.argsort(importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the 10 most important feature importances\n",
    "plt.barh(range(10), importances[sorted_idx], align='center')\n",
    "plt.yticks(range(10), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances of the 10 most important features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d70172",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_type == 'Random forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'random_state': [random_state]\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'learning_rate': [0.1, 0.05, 0.01],\n",
    "        'max_depth': [1, 3, 5, 7, 9],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'subsample': [0.1, 0.5, 1.0],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'loss': ['deviance', 'exponential']\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RandomizedSearchCV\n",
    "if perform_ho:\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=n_iter, cv=cv, random_state=random_state, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0b5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "if perform_ho:\n",
    "    random_search.fit(best_X_train, best_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Print the best score\n",
    "    print(\"Best Score: \",random_search.best_score_)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters: \",random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e830dc",
   "metadata": {},
   "source": [
    "##### Evaluate final model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52657df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Train model on training data\n",
    "    model = RandomForestClassifier(**random_search.best_params_) if best_model_type == 'Random forest' else GradientBoostingClassifier(**random_search.best_params_)\n",
    "    model.fit(best_X_train, best_y_train)\n",
    "    predictions = model.predict(best_X_test)\n",
    "    \n",
    "    # Evaluate model on validation data\n",
    "    print(f'Accuracy: {accuracy_score(best_y_test, predictions)}')\n",
    "    print(f\"PPV (precision): {precision_score(best_y_test, predictions, average='weighted')}\")\n",
    "    print(f\"Sensitivity (recall): {recall_score(best_y_test, predictions, average='weighted')}\")\n",
    "    print(f\"F1 score: {f1_score(best_y_test, predictions, average='weighted')}\")\n",
    "\n",
    "    print(classification_report(best_y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd5271",
   "metadata": {},
   "source": [
    "##### Evaluate final model on hold-out test data (trained on train and validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b14afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Train model on training+validation data\n",
    "    final_model = RandomForestClassifier(**random_search.best_params_) if best_model_type == 'Random forest' else GradientBoostingClassifier(**random_search.best_params_)\n",
    "    final_model.fit(target_X_s[target][best_i-1], target_y_s[target])\n",
    "    predictions = final_model.predict(target_X_s_test[target][best_i-1])\n",
    "    \n",
    "    # Evaluate model on hold-out test data\n",
    "    print(f'Accuracy: {accuracy_score(target_y_s_test[target], predictions)}')\n",
    "    print(f\"PPV (precision): {precision_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "    print(f\"Sensitivity (recall): {recall_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "    print(f\"F1 score: {f1_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "\n",
    "    print(classification_report(target_y_s_test[target], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c40b20",
   "metadata": {},
   "source": [
    "##### Plot feature importances of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    feature_names = list(best_X_train.columns)\n",
    "    importances = final_model.feature_importances_\n",
    "\n",
    "    # Sort importances and get the indices of the 10 most important features\n",
    "    sorted_idx = np.argsort(importances)[-10:]\n",
    "\n",
    "    # Create a bar plot of the 10 most important feature importances\n",
    "    plt.barh(range(10), importances[sorted_idx], align='center')\n",
    "    plt.yticks(range(10), [feature_names[i] for i in sorted_idx])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Feature Importances of the 10 most important features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa39a4b",
   "metadata": {},
   "source": [
    "### Target 2: Höchster Beatmungsbedarf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d512519",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 2\n",
    "X_s = target_X_s[target]\n",
    "y = target_y_s[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf376c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_results = {\n",
    "    'feature_subgroup': [],\n",
    "    'model': [],\n",
    "    'reference': [],\n",
    "    'accuracy': [],\n",
    "    'PPV': [],\n",
    "    'sensitivity': [],\n",
    "    'f1_score': [],\n",
    "    'p-value': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_model_type, best_i, best_X_train, best_y_train, best_X_test, best_y_test, best_acc = None, None, None, None, None, None, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, X in enumerate(X_s):\n",
    "    print(f'Feature subset {i+1}')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    for model_type in ['Random forest', 'Gradient boosting']:\n",
    "        print(model_type)\n",
    "        model = RandomForestClassifier(random_state=random_state) if model_type == 'Random forest' else GradientBoostingClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Perform McNemar significance test\n",
    "        majority_vote = np.array([y_test.mode()[0]] * len(y_test))\n",
    "        reference = accuracy_score(y_test, majority_vote)\n",
    "        d_results['reference'].append(reference)\n",
    "        mcnemar_result = mcnemar(table=[[sum(y_test & predictions), sum(~y_test & predictions)],\n",
    "                                      [sum(y_test & ~majority_vote), sum(~y_test & ~majority_vote)]], correction=True)\n",
    "        p_value = mcnemar_result.pvalue\n",
    "        d_results['p-value'].append(p_value)\n",
    "        \n",
    "        d_results['model'].append(model_type)\n",
    "\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        d_results['feature_subgroup'].append(i+1)\n",
    "        d_results['accuracy'].append(acc)\n",
    "        d_results['PPV'].append(precision_score(y_test, predictions, average='weighted'))\n",
    "        d_results['sensitivity'].append(recall_score(y_test, predictions, average='weighted'))\n",
    "        d_results['f1_score'].append(f1_score(y_test, predictions, average='weighted'))\n",
    "        print(f'Accuracy: {acc}')\n",
    "        print(classification_report(y_test, predictions))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_i = i+1\n",
    "            best_X_train = X_train\n",
    "            best_y_train = y_train\n",
    "            best_X_test = X_test\n",
    "            best_y_test = y_test\n",
    "            best_model = model\n",
    "            best_model_type = model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best accuracy: {best_acc}\\nBest model type: {best_model_type}\\nBest feature subset: {best_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(d_results)\n",
    "\n",
    "d_results_restructured = {\n",
    "    'feature_subset': [],\n",
    "    'accuracy': [],\n",
    "    'sensitivity': [],\n",
    "    'PPV': []\n",
    "}\n",
    "\n",
    "for f in [1,2,3,4,5,6]:\n",
    "    d_results_restructured['feature_subset'].append(f)\n",
    "    for metric in ['accuracy', 'sensitivity', 'PPV']:\n",
    "        rf = results[(results['feature_subgroup'] == f) & (results['model'] == 'Random forest')][metric].reset_index(drop=True).iloc[0]\n",
    "        gb = results[(results['feature_subgroup'] == f) & (results['model'] == 'Gradient boosting')][metric].reset_index(drop=True).iloc[0]\n",
    "        m_str = f'{gb*100:.2f}% ({rf*100:.2f}%)'\n",
    "        d_results_restructured[metric].append(m_str)\n",
    "\n",
    "pd.DataFrame(d_results_restructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ace4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddac941",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(best_X_train.columns)\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Sort importances and get the indices of the 10 most important features\n",
    "sorted_idx = np.argsort(importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the 10 most important feature importances\n",
    "plt.barh(range(10), importances[sorted_idx], align='center')\n",
    "plt.yticks(range(10), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances of the 10 most important features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376dadf",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8400a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_type == 'Random forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'random_state': [random_state]\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'learning_rate': [0.1, 0.05, 0.01],\n",
    "        'max_depth': [1, 3, 5, 7, 9],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'subsample': [0.1, 0.5, 1.0],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'loss': ['deviance', 'exponential']\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e90ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RandomizedSearchCV\n",
    "if perform_ho:\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=n_iter, cv=cv, random_state=random_state, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27818f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "if perform_ho:\n",
    "    random_search.fit(best_X_train, best_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559cbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Print the best score\n",
    "    print(\"Best Score: \",random_search.best_score_)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters: \",random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ce438",
   "metadata": {},
   "source": [
    "##### Evaluate final model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Train model on training data\n",
    "    model = RandomForestClassifier(**random_search.best_params_) if best_model_type == 'Random forest' else GradientBoostingClassifier(**random_search.best_params_)\n",
    "    model.fit(best_X_train, best_y_train)\n",
    "    predictions = model.predict(best_X_test)\n",
    "    \n",
    "    # Evaluate model on validation data\n",
    "    print(f'Accuracy: {accuracy_score(best_y_test, predictions)}')\n",
    "    print(f\"PPV (precision): {precision_score(best_y_test, predictions, average='weighted')}\")\n",
    "    print(f\"Sensitivity (recall): {recall_score(best_y_test, predictions, average='weighted')}\")\n",
    "    print(f\"F1 score: {f1_score(best_y_test, predictions, average='weighted')}\")\n",
    "\n",
    "    print(classification_report(best_y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceacc210",
   "metadata": {},
   "source": [
    "##### Evaluate final model on hold-out test data (trained on train and validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ee589",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Train model on training+validation data\n",
    "    final_model = RandomForestClassifier(**random_search.best_params_) if best_model_type == 'Random forest' else GradientBoostingClassifier(**random_search.best_params_)\n",
    "    final_model.fit(target_X_s[target][best_i-1], target_y_s[target])\n",
    "    predictions = final_model.predict(target_X_s_test[target][best_i-1])\n",
    "    \n",
    "    # Evaluate model on hold-out test data\n",
    "    print(f'Accuracy: {accuracy_score(target_y_s_test[target], predictions)}')\n",
    "    print(f\"PPV (precision): {precision_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "    print(f\"Sensitivity (recall): {recall_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "    print(f\"F1 score: {f1_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "\n",
    "    print(classification_report(target_y_s_test[target], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292116fe",
   "metadata": {},
   "source": [
    "##### Plot feature importances of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    feature_names = list(best_X_train.columns)\n",
    "    importances = final_model.feature_importances_\n",
    "\n",
    "    # Sort importances and get the indices of the 10 most important features\n",
    "    sorted_idx = np.argsort(importances)[-10:]\n",
    "\n",
    "    # Create a bar plot of the 10 most important feature importances\n",
    "    plt.barh(range(10), importances[sorted_idx], align='center')\n",
    "    plt.yticks(range(10), [feature_names[i] for i in sorted_idx])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Feature Importances of the 10 most important features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d3452",
   "metadata": {},
   "source": [
    "### Target 3: Binärer Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 3\n",
    "X_s = target_X_s[target]\n",
    "y = target_y_s[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9968773",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_results = {\n",
    "    'feature_subgroup': [],\n",
    "    'model': [],\n",
    "    'reference': [],\n",
    "    'accuracy': [],\n",
    "    'PPV': [],\n",
    "    'sensitivity': [],\n",
    "    'f1_score': [],\n",
    "    'p-value': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_model_type, best_i, best_X_train, best_y_train, best_X_test, best_y_test, best_acc = None, None, None, None, None, None, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, X in enumerate(X_s):\n",
    "    print(f'Feature subset {i+1}')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    for model_type in ['Random forest', 'Gradient boosting']:\n",
    "        print(model_type)\n",
    "        model = RandomForestClassifier(random_state=random_state) if model_type == 'Random forest' else GradientBoostingClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Perform McNemar significance test\n",
    "        majority_vote = np.array([y_test.mode()[0]] * len(y_test))\n",
    "        reference = accuracy_score(y_test, majority_vote)\n",
    "        d_results['reference'].append(reference)\n",
    "        mcnemar_result = mcnemar(table=[[sum(y_test & predictions), sum(~y_test & predictions)],\n",
    "                                      [sum(y_test & ~majority_vote), sum(~y_test & ~majority_vote)]], correction=True)\n",
    "        p_value = mcnemar_result.pvalue\n",
    "        d_results['p-value'].append(p_value)\n",
    "        \n",
    "        d_results['model'].append(model_type)\n",
    "\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        d_results['feature_subgroup'].append(i+1)\n",
    "        d_results['accuracy'].append(acc)\n",
    "        d_results['PPV'].append(precision_score(y_test, predictions, average='weighted'))\n",
    "        d_results['sensitivity'].append(recall_score(y_test, predictions, average='weighted'))\n",
    "        d_results['f1_score'].append(f1_score(y_test, predictions, average='weighted'))\n",
    "        print(f'Accuracy: {acc}')\n",
    "        print(classification_report(y_test, predictions))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_i = i+1\n",
    "            best_X_train = X_train\n",
    "            best_y_train = y_train\n",
    "            best_X_test = X_test\n",
    "            best_y_test = y_test\n",
    "            best_model = model\n",
    "            best_model_type = model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed560c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best accuracy: {best_acc}\\nBest model type: {best_model_type}\\nBest feature subset: {best_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52292f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(d_results)\n",
    "\n",
    "d_results_restructured = {\n",
    "    'feature_subset': [],\n",
    "    'accuracy': [],\n",
    "    'sensitivity': [],\n",
    "    'PPV': []\n",
    "}\n",
    "\n",
    "for f in [1,2,3,4,5,6]:\n",
    "    d_results_restructured['feature_subset'].append(f)\n",
    "    for metric in ['accuracy', 'sensitivity', 'PPV']:\n",
    "        rf = results[(results['feature_subgroup'] == f) & (results['model'] == 'Random forest')][metric].reset_index(drop=True).iloc[0]\n",
    "        gb = results[(results['feature_subgroup'] == f) & (results['model'] == 'Gradient boosting')][metric].reset_index(drop=True).iloc[0]\n",
    "        m_str = f'{gb*100:.2f}% ({rf*100:.2f}%)'\n",
    "        d_results_restructured[metric].append(m_str)\n",
    "\n",
    "pd.DataFrame(d_results_restructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(best_X_train.columns)\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Sort importances and get the indices of the 10 most important features\n",
    "sorted_idx = np.argsort(importances)[-10:]\n",
    "\n",
    "# Create a bar plot of the 10 most important feature importances\n",
    "plt.barh(range(10), importances[sorted_idx], align='center')\n",
    "plt.yticks(range(10), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances of the 10 most important features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4627a",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40681da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_type == 'Random forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'random_state': [random_state]\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'learning_rate': [0.1, 0.05, 0.01],\n",
    "        'max_depth': [1, 3, 5, 7, 9],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'subsample': [0.1, 0.5, 1.0],\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'loss': ['deviance', 'exponential']\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f71d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RandomizedSearchCV\n",
    "if perform_ho:\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=n_iter, cv=cv, random_state=random_state, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9858bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "if perform_ho:\n",
    "    random_search.fit(best_X_train, best_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Print the best score\n",
    "    print(\"Best Score: \",random_search.best_score_)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters: \",random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635fd1a",
   "metadata": {},
   "source": [
    "##### Evaluate final model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671eb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Train model on training data\n",
    "    model = RandomForestClassifier(**random_search.best_params_) if best_model_type == 'Random forest' else GradientBoostingClassifier(**random_search.best_params_)\n",
    "    model.fit(best_X_train, best_y_train)\n",
    "    predictions = model.predict(best_X_test)\n",
    "    \n",
    "    # Evaluate model on validation data\n",
    "    print(f'Accuracy: {accuracy_score(best_y_test, predictions)}')\n",
    "    print(f\"PPV (precision): {precision_score(best_y_test, predictions, average='weighted')}\")\n",
    "    print(f\"Sensitivity (recall): {recall_score(best_y_test, predictions, average='weighted')}\")\n",
    "    print(f\"F1 score: {f1_score(best_y_test, predictions, average='weighted')}\")\n",
    "\n",
    "    print(classification_report(best_y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b8106c",
   "metadata": {},
   "source": [
    "##### Evaluate final model on hold-out test data (trained on train and validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    # Train model on training+validation data\n",
    "    final_model = RandomForestClassifier(**random_search.best_params_) if best_model_type == 'Random forest' else GradientBoostingClassifier(**random_search.best_params_)\n",
    "    final_model.fit(target_X_s[target][best_i-1], target_y_s[target])\n",
    "    predictions = final_model.predict(target_X_s_test[target][best_i-1])\n",
    "    \n",
    "    # Evaluate model on hold-out test data\n",
    "    print(f'Accuracy: {accuracy_score(target_y_s_test[target], predictions)}')\n",
    "    print(f\"PPV (precision): {precision_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "    print(f\"Sensitivity (recall): {recall_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "    print(f\"F1 score: {f1_score(target_y_s_test[target], predictions, average='weighted')}\")\n",
    "\n",
    "    print(classification_report(target_y_s_test[target], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671730ca",
   "metadata": {},
   "source": [
    "##### Plot feature importances of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_ho:\n",
    "    feature_names = list(best_X_train.columns)\n",
    "    importances = final_model.feature_importances_\n",
    "\n",
    "    # Sort importances and get the indices of the 10 most important features\n",
    "    sorted_idx = np.argsort(importances)[-10:]\n",
    "\n",
    "    # Create a bar plot of the 10 most important feature importances\n",
    "    plt.barh(range(10), importances[sorted_idx], align='center')\n",
    "    plt.yticks(range(10), [feature_names[i] for i in sorted_idx])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Feature Importances of the 10 most important features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a60d3",
   "metadata": {},
   "source": [
    "##### Location-based accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_count = raw_data.iloc[target_split_indices[3]['test']]['Location'].value_counts().to_frame().reset_index(drop=False)\n",
    "locations = [loc for loc in location_count['index'].unique() if location_count[location_count['index'] == loc]['Location'].reset_index(drop=True).iloc[0] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X_s_test_loc = target_X_s_test[target][best_i-1]\n",
    "target_X_s_test_loc['Location'] = list(raw_data.iloc[target_split_indices[target]['test']]['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea78611",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y_s_test_loc = pd.DataFrame({'y': target_y_s_test[target], 'location': list(raw_data.iloc[target_split_indices[target]['test']]['Location'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9466ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_accuracies = []\n",
    "for loc in locations:\n",
    "    tmp_loc_data_X = target_X_s_test_loc[target_X_s_test_loc['Location'] == loc]\n",
    "    tmp_loc_data_y = target_y_s_test_loc[target_X_s_test_loc['Location'] == loc]\n",
    "    tmp_loc_data_X.drop('Location', inplace=True, axis=1)\n",
    "    \n",
    "    loc_predictions = final_model.predict(tmp_loc_data_X)\n",
    "    loc_acc = accuracy_score(tmp_loc_data_y['y'], loc_predictions)\n",
    "    loc_accuracies.append(loc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Location-specific results STD: {np.array(loc_accuracies).std()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
